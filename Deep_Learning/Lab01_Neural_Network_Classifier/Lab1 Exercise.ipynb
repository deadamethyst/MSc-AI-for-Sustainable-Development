{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63d58b3d",
   "metadata": {},
   "source": [
    "# MNIST classifier **Exercise**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "In this exercise, you will apply what you've learned to build, train, and evaluate a neural network to classify handwritten digits from the famous MNIST dataset.\n",
    "\n",
    "\n",
    "# Step 1: Import the libraries\n",
    "\n",
    "Step 1: Setup and Imports\n",
    "First, we import the necessary libraries and, most importantly, set up our device. This ensures our code will use a GPU for faster training if one is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afb18fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Core PyTorch and data handling libraries ---\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# --- Visualization and analysis ---\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Device and reproducibility ---\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd52e531",
   "metadata": {},
   "source": [
    "## Step 2 — Prepare the dataset transforms and load MNIST\n",
    "\n",
    "We will scale images to `[0,1]` with `ToTensor()` and then **standardize** with mean/std for MNIST. Keep these lines unchanged for the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d272a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST statistics (train set)\n",
    "mnist_mean = 0.1307\n",
    "mnist_std = 0.3081\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # Resize the image to 28x28 pixels\n",
    "    transforms.Resize((28, 28)),\n",
    "    # Convert the image to a PyTorch tensor\n",
    "    # ** Fill in the code below **\n",
    "    # Normalize the image with mean and standard deviation\n",
    "    #** Fill in the code below **\n",
    "])\n",
    "\n",
    "train_set = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
    "test_set  = datasets.MNIST(root='data', train=False, download=True, transform=transform)\n",
    "\n",
    "print('Train samples:', len(train_set))\n",
    "print('Test samples :', len(test_set))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28944b4c",
   "metadata": {},
   "source": [
    "### Visualize some training samples\n",
    "The images are normalized. The helper function below **unnormalizes** them before plotting so they appear correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b3fbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_normalized(tensor_img, mean=mnist_mean, std=mnist_std):\n",
    "    \"\"\"Unnormalize a CxHxW tensor and plot it as HxW (grayscale)\"\"\"\n",
    "    img = tensor_img.clone().cpu().numpy()\n",
    "    img = img * std + mean\n",
    "    plt.imshow(img.squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "cols, rows = 4, 4\n",
    "for i in range(1, cols*rows + 1):\n",
    "    idx = random.randint(0, len(train_set)-1)\n",
    "    img, label = train_set[idx]\n",
    "    plt.subplot(rows, cols, i)\n",
    "    imshow_normalized(img)\n",
    "    plt.title(f\"Label: {label}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143a68ca",
   "metadata": {},
   "source": [
    "## Step 3 — Create DataLoaders\n",
    "\n",
    "Create `DataLoader`s for training and testing. Leave `shuffle=True` for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7832ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_loader = #** Fill in the code below **\n",
    "test_loader  = #** Fill in the code below **\n",
    "\n",
    "print('Train batches:', len(train_loader))\n",
    "print('Test  batches:', len(test_loader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54d67c7",
   "metadata": {},
   "source": [
    "## Step 4 — Define your network \n",
    "\n",
    "Implement a PyTorch `nn.Module` for classification. \n",
    "\n",
    "Below is a skeleton: fill in the `TODO` parts.\n",
    "\n",
    "Hints:\n",
    "- Input size is `28*28` after flattening.\n",
    "- Output size must be `10` (classes 0..9).\n",
    "- Use `nn.ReLU()` activations and `nn.Linear` layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f443f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # TODO: build your network layers here\n",
    "        \n",
    "        \n",
    "        raise NotImplementedError(\"Define your network layers in __init__\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: implement forward pass\n",
    "        \n",
    "        \n",
    "        raise NotImplementedError(\"Implement forward() to return logits\")\n",
    "\n",
    "# Initialize model (students should implement the class above first)\n",
    "try:\n",
    "    model = NeuralNetwork().to(device)\n",
    "    print(model)\n",
    "except NotImplementedError as e:\n",
    "    print('Model not defined yet — fill the TODO in the class above.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2991a32c",
   "metadata": {},
   "source": [
    "## Step 5 — Training setup \n",
    "\n",
    "Create the loss function, optimizer and a training loop. Fill the TODOs below. Use `nn.CrossEntropyLoss()` for the loss and `torch.optim.SGD` or `Adam` for the optimizer.\n",
    "\n",
    "Implement `train_loop` and `test_loop` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff11d4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters (feel free to experiment)\n",
    "learning_rate = 1e-2\n",
    "epochs = 10\n",
    "\n",
    "# TODO: choose loss and optimizer\n",
    "loss_fn = None  # TODO\n",
    "optimizer = None  # TODO\n",
    "\n",
    "\n",
    "# Optional, feel free to implement something else you are comfortable with\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, device):\n",
    "    \"\"\"Train for one epoch. Return (avg_loss, accuracy_fraction).\n",
    "    Implement per-sample loss averaging and exact accuracy counting.\n",
    "    \"\"\"\n",
    "    # TODO: implement training loop\n",
    "    raise NotImplementedError(\"Implement train_loop\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, device):\n",
    "    \"\"\"Evaluate on validation/test set. Return (avg_loss, accuracy_fraction).\"\"\"\n",
    "    # TODO: implement test loop\n",
    "    raise NotImplementedError(\"Implement test_loop\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd0e97a",
   "metadata": {},
   "source": [
    "### Run training \n",
    "\n",
    "Fill the training loop above. Print per-epoch train/test loss and accuracy. Do not run this cell until you implemented the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe37e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training: implement the train_loop/test_loop first!\n",
    "try:\n",
    "    for epoch in range(1, epochs+1):\n",
    "        print(f\"Epoch {epoch}/{epochs}\")\n",
    "        train_loss, train_acc = train_loop(train_loader, model, loss_fn, optimizer, device)\n",
    "        test_loss, test_acc = test_loop(test_loader, model, loss_fn, device)\n",
    "        print(f\"Train loss: {train_loss:.4f}, Train acc: {100*train_acc:.2f}% | Test loss: {test_loss:.4f}, Test acc: {100*test_acc:.2f}%\")\n",
    "except NotImplementedError:\n",
    "    print('Training loop or model not implemented yet. Fill the TODOs above before running training.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e55a438",
   "metadata": {},
   "source": [
    "## Step 6 — Evaluate & visualize (***Student Task***)\n",
    "\n",
    "Once you have trained the model, compute and plot the learning curves, confusion matrix and some sample predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf40f884",
   "metadata": {},
   "source": [
    "## Step 7 — Saving and loading models\n",
    "\n",
    "Once you're satisfied with the trained model, save the `state_dict`. The code below is provided — use it after training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98570cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: saving and loading (run AFTER training)\n",
    "PATH = 'mnist_model_student.pth'\n",
    "# torch.save(model.state_dict(), PATH)\n",
    "# To load:\n",
    "# model_loaded = NeuralNetwork().to(device)\n",
    "# model_loaded.load_state_dict(torch.load(PATH))\n",
    "# model_loaded.eval()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb30797",
   "metadata": {},
   "source": [
    "### Final notes for students\n",
    "- Try different architectures, learning rates, optimizers and schedulers.\n",
    "- Experiment with batch size and number of epochs.\n",
    "- Compare normalizing with dataset stats vs simple `mean=0.5,std=0.5`.\n",
    "- Critically analyze your results, how is your model performing? How can it be improved?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pgta (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
